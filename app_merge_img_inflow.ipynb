{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import datetime  \n",
    "from datetime import date \n",
    "import calendar \n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotina que carrega os dados do DAE, com vazao do rio e que le o valor da coluna \"intervalo\"\n",
    "#depois criar:\n",
    "# - duas novas colunas, com data e com hora da vazao medida\n",
    "# - tres colunas, com categoria, faixa e diretorio\n",
    "def format_dados_vazao_DAE(pArqCsv,agrup=10):\n",
    "    \n",
    "    data_dae=pd.read_csv(pArqCsv)\n",
    "    data_dae=data_dae.dropna()\n",
    "    \n",
    "    #carrega a coluna intervalo, que tem data/hora da leitura da vazão. Ex: 2018-01-01 03:00:00 UTC\n",
    "    lst_data=list(data_dae['intervalo'])\n",
    "    lst_valor=list(data_dae['valor'])\n",
    "    qtd = len(lst_data)\n",
    "    num = 0\n",
    "    lstdia=[]\n",
    "    lsthora=[]\n",
    "    lstano=[]\n",
    "    lstdir=[]\n",
    "    \n",
    "    #faz um loop nos intervalos e separa o dia e a hora, e salva em uma lista\n",
    "    while num<qtd:\n",
    "        dia_ano = datetime.datetime(int(lst_data[num][:4]),int(lst_data[num][5:7]),int(lst_data[num][8:10])).strftime(\"%j\")\n",
    "        hora=lst_data[num][11:13]        \n",
    "        ano=lst_data[num][0:4]\n",
    "        lstano.append(str(ano))\n",
    "        lstdia.append(str(dia_ano))\n",
    "        lsthora.append(str(hora))\n",
    "        valor = str(int(round(lst_valor[num],0)))        \n",
    "        lstdir.append(int(valor))\n",
    "        num+=1\n",
    "\n",
    "    #com os dados carregados de data e hora, cria 2 colunas no dataframe do DAE    \n",
    "    data_dae['ano']=lstano\n",
    "    data_dae['dia_ano']=lstdia\n",
    "    data_dae['hora']=lsthora    \n",
    "    data_dae['categoria']=lstdir\n",
    "    \n",
    "    #verificar qual o diretorio que a imagem deve ser movida\n",
    "    if agrup==10:\n",
    "        vbins=list(range(0, 470, 10))\n",
    "        vlabels=list(range(0, 460, 10))    \n",
    "    elif agrup==5:\n",
    "        vbins=list(range(0, 460, 5))\n",
    "        vlabels=list(range(0, 455, 5))\n",
    "    elif agrup==3:\n",
    "        vbins=list(range(0, 456, 3))\n",
    "        vlabels=list(range(0, 453, 3))        \n",
    "    elif agrup==2:\n",
    "        vbins=list(range(0, 470, 2))\n",
    "        vlabels=list(range(0, 468, 2))   \n",
    "        \n",
    "    data_dae['diretorio'] = pd.cut(x=data_dae['categoria'],bins=vbins, labels=vlabels)\n",
    "    data_dae['faixa'] = pd.cut(x=data_dae['categoria'], bins=vbins)    \n",
    "    \n",
    "    return data_dae\n",
    "\n",
    "def gera_lista_arquivos_goes(ano1,dia1ini,dia1fim,ano2,dia2ini,dia2fim,ano3,dia3ini,dia3fim):\n",
    "    dia=dia1ini\n",
    "    dia_fim=dia1fim\n",
    "    ano = ano1\n",
    "    lstfiles=[]\n",
    "    lstano=[]\n",
    "    lstdia=[]\n",
    "    lsthora=[]\n",
    "    while dia<=dia_fim: \n",
    "        dia_pasta='%03d'%(dia)  \n",
    "        \n",
    "        #arquivos baixados GOES do ano de 2020 e reduzidos de tamanho para 256x256\n",
    "        for file in glob.glob(\"imagesred/ch03/\"+str(ano)+\"/\"+str(dia_pasta)+\"/*.png\"):        \n",
    "            if file.find(\".png\")>0:  \n",
    "                pos=file.find(\"s\"+str(ano)+str(dia_pasta))            \n",
    "                hora = file[int(pos)+8:int(pos)+8+2]            \n",
    "                lstfiles.append(file) \n",
    "                lstano.append(str(ano))\n",
    "                lstdia.append(str(dia_pasta))\n",
    "                lsthora.append(str(hora))\n",
    "        dia+=1    \n",
    "    dia=dia2ini\n",
    "    dia_fim=dia2fim\n",
    "    ano = ano2\n",
    "    while dia<=dia_fim: \n",
    "        dia_pasta='%03d'%(dia)  \n",
    "        \n",
    "        #arquivos baixados GOES do ano de 2020 e reduzidos de tamanho para 256x256\n",
    "        for file in glob.glob(\"imagesred/ch03/\"+str(ano)+\"/\"+str(dia_pasta)+\"/*.png\"):        \n",
    "            if file.find(\".png\")>0:  \n",
    "                pos=file.find(\"s\"+str(ano)+str(dia_pasta))            \n",
    "                hora = file[int(pos)+8:int(pos)+8+2]            \n",
    "                lstfiles.append(file) \n",
    "                lstano.append(str(ano))\n",
    "                lstdia.append(str(dia_pasta))\n",
    "                lsthora.append(str(hora))\n",
    "        dia+=1    \n",
    "\n",
    "    dia=dia3ini\n",
    "    dia_fim=dia3fim\n",
    "    ano = ano3\n",
    "    while dia<=dia_fim: \n",
    "        dia_pasta='%03d'%(dia)  \n",
    "        \n",
    "        #arquivos baixados GOES do ano de 2020 e reduzidos de tamanho para 256x256\n",
    "        for file in glob.glob(\"imagesred/ch03/\"+str(ano)+\"/\"+str(dia_pasta)+\"/*.png\"):        \n",
    "            if file.find(\".png\")>0:  \n",
    "                pos=file.find(\"s\"+str(ano)+str(dia_pasta))            \n",
    "                hora = file[int(pos)+8:int(pos)+8+2]            \n",
    "                lstfiles.append(file) \n",
    "                lstano.append(str(ano))\n",
    "                lstdia.append(str(dia_pasta))\n",
    "                lsthora.append(str(hora))\n",
    "        dia+=1    \n",
    "        \n",
    "    data_images=pd.DataFrame(data={'filename':lstfiles,'ano':lstano,'dia':lstdia,'hora':lsthora})\n",
    "    return data_images\n",
    "\n",
    "#une dados da lista de arquivos baixados do GOES com a lista de dados de vazao do DAE e gera um csv\n",
    "def gera_csv_lista_dados_imagens_treinamento_rna(Dados_DAE_Posto, Dados_Imagens_GOES,SiglaPosto,diamais=0,agrup=10):\n",
    "    data_dae = Dados_DAE_Posto\n",
    "    data_images = Dados_Imagens_GOES\n",
    "    \n",
    "    id_label=[]\n",
    "    value_label=[]\n",
    "    diretorio_img=[]\n",
    "    faixa_img=[]\n",
    "    not_found=0\n",
    "    for index, row in data_images.iterrows():\n",
    "        dia = row['dia']        \n",
    "        hora = row['hora']\n",
    "        ano = row['ano']         \n",
    "        \n",
    "        if int(diamais)>=1:\n",
    "            if int(dia)==365:\n",
    "                dia = '001'\n",
    "                ano = str(int(ano)+1)\n",
    "            else:                \n",
    "                dia=int(dia)+int(diamais)                \n",
    "                dia='%03d'%(dia)\n",
    "                dia=str(dia)\n",
    "            \n",
    "        #a imagem das 12hrs\n",
    "        if int(hora) == 12:\n",
    "            data_dae_1 = data_dae.loc[(data_dae['ano']==str(ano))&(data_dae['dia_ano']==str(dia))&(data_dae['hora']==str(hora))]\n",
    "            found=int(data_dae_1['hora'].count())\n",
    "            if found>0:  \n",
    "                valor = data_dae_1['valor'].values[0]\n",
    "                diretorio = data_dae_1['diretorio'].values[0]\n",
    "                faixa = data_dae_1['faixa'].values[0]\n",
    "\n",
    "                id_label.append(row['filename'])\n",
    "                value_label.append(str(valor))        \n",
    "                diretorio_img.append(str(diretorio))\n",
    "                faixa_img.append(str(faixa))\n",
    "            else:\n",
    "                not_found+=1\n",
    "                #print('not found vazao dia/hr:',dia,hora)\n",
    "                        \n",
    "    print('total - not found vazao dia/hr:',not_found)\n",
    "    \n",
    "    data_labels=pd.DataFrame(data={'filename':id_label\n",
    "                                   ,'valor_vazao':value_label\n",
    "                                   ,'diretorio':diretorio_img\n",
    "                                   ,'faixa':faixa_img\n",
    "                                  })   \n",
    "    data_labels.to_csv(\"data_train_rna_\"+str(SiglaPosto)+\".csv\")\n",
    "    print('gerado arquivo :'+ \"data_train_rna_\"+str(SiglaPosto)+\".csv\")\n",
    "    return data_labels, \"data_train_rna_\"+str(SiglaPosto)+\".csv\"\n",
    "\n",
    "#funcao para redimensionar arquivos para 255x255 pixels e \n",
    "#mover em diretorios conforme o valor de vazao\n",
    "def images_move_diretorio_digits(Csv_Train_Rna,SiglaPosto):\n",
    "    data_labels=pd.read_csv(Csv_Train_Rna)\n",
    "    listafile=[]\n",
    "    listvalue=[]\n",
    "    listdirName=[]\n",
    "    dirRaiz = SiglaPosto\n",
    "    \n",
    "    #criar diretorio Raiz caso nao exista\n",
    "    print('dirRaiz',dirRaiz)\n",
    "    if not os.path.exists(dirRaiz):\n",
    "        os.makedirs(dirRaiz)  \n",
    "\n",
    "    for index, row in data_labels.iterrows():\n",
    "        \n",
    "        filename=row['filename']\n",
    "        valor=row['valor_vazao']     \n",
    "        dirName=str(row['diretorio'])\n",
    "        listdirName.append(dirName)\n",
    "        if not os.path.exists(dirRaiz+\"/\"+dirName):        \n",
    "            os.makedirs(dirRaiz+\"/\"+dirName)\n",
    "            print(str(dirRaiz+\"/\"+dirName))\n",
    "\n",
    "        image = Image.open(filename)  \n",
    "        \n",
    "        #as imagens ja foram redimensionadas, antes pela funcao ()\n",
    "        #new_image = image.resize((255, 255), PIL.Image.ANTIALIAS)\n",
    "        new_image = image\n",
    "        \n",
    "        newfilename=dirRaiz+\"/\"+dirName+'/'+(filename[-77:])        \n",
    "        new_image.save(newfilename)\n",
    "        print('image save :'+newfilename)\n",
    "        listafile.append(newfilename)    \n",
    "        listvalue.append(valor)\n",
    "\n",
    "    data_labels=pd.DataFrame(data={'id':listafile,'label':listvalue})   \n",
    "    data_labels.to_csv(\"data_label_train_resize_\"+dirRaiz+\".csv\")\n",
    "    print(\"gerado arquivo: data_label_train_resize_\"+dirRaiz+\".csv\")\n",
    "    #print(\"redimensionar/mover arquivos finalizado!!\")\n",
    "    print(\"mover arquivos finalizado!!\")\n",
    "\n",
    "          \n",
    "# Driver program \n",
    "#date = '31 03 2019'\n",
    "#print(findDay(date))\n",
    "def findDay(date): \n",
    "    day, month, year = (int(i) for i in date.split(' '))     \n",
    "    born = datetime.date(year, month, day) \n",
    "    return born.strftime(\"%j\") #day of year  \n",
    "\n",
    "#import numpy as np\n",
    "#x = np.array(listdirName) \n",
    "#print(np.unique(x)) \n",
    "\n",
    "def run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto):\n",
    "    \n",
    "    data_dae = format_dados_vazao_DAE(csv_daae,agrup)\n",
    "    data_images = gera_lista_arquivos_goes(2018,1,365,2019,1,365,2020,1,365)\n",
    "    data_train,nome_csv = gera_csv_lista_dados_imagens_treinamento_rna(data_dae, data_images,sigla_Posto,diamais,agrup)\n",
    "    data_train['diretorio']=data_train['diretorio'].astype(int)\n",
    "    #mineração dos dados - parte 1\n",
    "    data_train = data_train[data_train['diretorio']<data_dae['valor'].median()*2] \n",
    "    #mineração dos dados - parte 2\n",
    "    a = data_train.groupby('diretorio').count().sort_values('diretorio')\n",
    "    dir_abaixo_10 = list(a[a['filename']<=10].index)\n",
    "    for dir10 in dir_abaixo_10:\n",
    "        data_train = data_train[data_train['diretorio']!=dir10] \n",
    "    data_train.to_csv(\"data_train_rna_\"+str(sigla_Posto)+\".csv\")\n",
    "    #%cd /tf/goes\n",
    "    images_move_diretorio_digits(nome_csv,sigla_Posto)\n",
    "    data_train.groupby('diretorio').count().sort_values('diretorio')\n",
    "    \n",
    "    print(\"Done - \" + sigla_Posto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done - FSB_12h_m0\n",
      "Done - GAV_12h_m0\n",
      "Done - IVR_12h_m0\n",
      "Done - FSB_12h_m1\n",
      "Done - GAV_12h_m1\n",
      "Done - IVR_12h_m1\n",
      "Done - FSB_12h_m7\n",
      "Done - GAV_12h_m7\n",
      "Done - IVR_12h_m7\n"
     ]
    }
   ],
   "source": [
    "diamais = 0\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_FSB.csv'\n",
    "sigla_Posto = 'FSB_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 0\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_GAV.csv'\n",
    "sigla_Posto = 'GAV_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 0\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_IVR.csv'\n",
    "sigla_Posto = 'IVR_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 1\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_FSB.csv'\n",
    "sigla_Posto = 'FSB_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 1\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_GAV.csv'\n",
    "sigla_Posto = 'GAV_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 1\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_IVR.csv'\n",
    "sigla_Posto = 'IVR_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 7\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_FSB.csv'\n",
    "sigla_Posto = 'FSB_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 7\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_GAV.csv'\n",
    "sigla_Posto = 'GAV_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n",
    "diamais = 7\n",
    "agrup=5\n",
    "csv_daae='dados_plu_2018-01-01_2020-12-31_IVR.csv'\n",
    "sigla_Posto = 'IVR_12h_m'+str(diamais)\n",
    "run_merge_img_inflow(diamais,agrup,csv_daae,sigla_Posto)\n",
    "#-----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
